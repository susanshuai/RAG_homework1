import pandas as pd
import json
from langchain.schema import Document
from langchain.chains import ConversationalRetrievalChain
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
import pandas as pd
import json
from google.colab import userdata

print("Loading documents")
# Loading documents from local disk

data = pd.read_csv("./data/books_0.Best_Books_Ever.csv")
data_dict = data.to_json(orient='index')
data_dict = json.loads(data_dict)
data_list = list(data_dict.values())


# Convert dictionary values into chunks

documents = []

for d in data_list:
  #print(d.get('description',""))
  if 'rating' in d.keys():
    
    doc = Document(
        page_content = d.get('description',""),
        metadata = {'rating':d['rating']},
        source = d.get('title',"")
    )
    documents.append(doc)

chunks = documents

print("Creating embeddings")
# Create embeddings for each chunk
embeddings = OpenAIEmbeddings(api_key = userdata.get('OPENAI_API_KEY'))
vectorstore = Chroma.from_documents(chunks, embeddings)
retriever = vectorstore.as_retriever()

print("Creating chains")
llm = ChatOpenAI(api_key = userdata.get('OPENAI_API_KEY'))
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
conversation = ConversationalRetrievalChain.from_llm(
    llm, retriever=retriever, memory=memory, verbose=False)

while(True):
    user_input = input("> ")
    if user_input == "exit":
      break
    result = conversation.invoke(user_input)
    print(result["answer"])
